#!/usr/bin/env python3
import os
import json
import re
import base64
import time
import socket
from urllib.parse import urlparse, parse_qs
from concurrent.futures import ThreadPoolExecutor, as_completed

class GitHubNodeTester:
    def __init__(self):
        self.sub_file = "sub.txt"  # åŒæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶
        self.timeout = 8
        self.max_workers = 3  # GitHub Actionsé™åˆ¶å¹¶å‘æ•°
        self.results = []
    
    def check_sub_file(self):
        """æ£€æŸ¥sub.txtæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        if not os.path.exists(self.sub_file):
            print(f"âŒ é”™è¯¯: å½“å‰ç›®å½•ä¸‹æ‰¾ä¸åˆ° {self.sub_file}")
            print(f"ğŸ“ å½“å‰ç›®å½•æ–‡ä»¶åˆ—è¡¨:")
            for file in os.listdir('.'):
                print(f"   - {file}")
            return False
        return True
    
    def read_subscription(self):
        """è¯»å–è®¢é˜…æ–‡ä»¶å†…å®¹"""
        try:
            with open(self.sub_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            print(f"âœ… æˆåŠŸè¯»å– {self.sub_file}")
            print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
            return content
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def extract_nodes(self, content):
        """æå–æ‰€æœ‰èŠ‚ç‚¹é“¾æ¥"""
        patterns = [
            r'vmess://[A-Za-z0-9+/=]+',
            r'vless://[^\s]+',
            r'trojan://[^\s]+', 
            r'ss://[^\s]+',
            r'hysteria2://[^\s]+'
        ]
        
        nodes = []
        for pattern in patterns:
            matches = re.findall(pattern, content)
            nodes.extend(matches)
        
        print(f"ğŸ” å‘ç° {len(nodes)} ä¸ªèŠ‚ç‚¹")
        return nodes
    
    def safe_parse_vmess(self, vmess_url):
        """å®‰å…¨è§£æVMess"""
        try:
            encoded = vmess_url[8:]  # å»æ‰'vmess://'
            padding = 4 - len(encoded) % 4
            if padding != 4:
                encoded += '=' * padding
            
            decoded = base64.b64decode(encoded).decode('utf-8', errors='ignore')
            config = json.loads(decoded)
            
            return {
                'type': 'vmess',
                'address': config.get('add', ''),
                'port': config.get('port', ''),
                'remark': config.get('ps', '')[:20]
            }
        except:
            return {'error': 'è§£æå¤±è´¥'}
    
    def safe_parse_vless_trojan(self, url):
        """è§£æVLESS/Trojan"""
        try:
            parsed = urlparse(url)
            return {
                'type': 'vless' if url.startswith('vless') else 'trojan',
                'address': parsed.hostname,
                'port': parsed.port,
                'protocol': parsed.scheme
            }
        except:
            return {'error': 'è§£æå¤±è´¥'}
    
    def safe_parse_ss(self, ss_url):
        """è§£æShadowsocks"""
        try:
            if '@' in ss_url:
                parts = ss_url[5:].split('@')  # å»æ‰'ss://'
                host_port = parts[1].split('#')[0]
                host, port = host_port.split(':')
                return {
                    'type': 'ss',
                    'address': host,
                    'port': port
                }
            return {'error': 'è§£æå¤±è´¥'}
        except:
            return {'error': 'è§£æå¤±è´¥'}
    
    def parse_node(self, node_url):
        """ç»Ÿä¸€è§£æèŠ‚ç‚¹"""
        if node_url.startswith('vmess://'):
            return self.safe_parse_vmess(node_url)
        elif node_url.startswith('vless://'):
            return self.safe_parse_vless_trojan(node_url)
        elif node_url.startswith('trojan://'):
            return self.safe_parse_vless_trojan(node_url)
        elif node_url.startswith('ss://'):
            return self.safe_parse_ss(node_url)
        elif node_url.startswith('hysteria2://'):
            return {'type': 'hysteria2', 'address': 'ç‰¹æ®Šåè®®'}
        else:
            return {'error': 'æœªçŸ¥åè®®'}
    
    def github_safe_connect_test(self, host, port):
        """GitHubç¯å¢ƒå®‰å…¨çš„è¿æ¥æµ‹è¯•"""
        try:
            start_time = time.time()
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(self.timeout)
            result = sock.connect_ex((host, int(port)))
            connect_time = (time.time() - start_time) * 1000
            sock.close()
            
            return result == 0, connect_time
        except:
            return False, None
    
    def test_single_node(self, node_url, index):
        """æµ‹è¯•å•ä¸ªèŠ‚ç‚¹"""
        # è§£æèŠ‚ç‚¹ä¿¡æ¯
        node_info = self.parse_node(node_url)
        
        if 'error' in node_info:
            return {
                'index': index,
                'url': node_url[:60] + '...',
                'info': node_info,
                'status': 'parse_error',
                'latency': None
            }
        
        # æµ‹è¯•è¿æ¥
        success, latency = self.github_safe_connect_test(
            node_info['address'], 
            node_info.get('port', 80)
        )
        
        status = 'success' if success else 'connect_failed'
        
        return {
            'index': index,
            'url': node_url[:60] + '...',
            'info': node_info,
            'status': status,
            'latency': latency
        }
    
    def run_test(self):
        """æ‰§è¡Œå®Œæ•´æµ‹è¯•æµç¨‹"""
        print("=" * 60)
        print("ğŸš€ GitHubèŠ‚ç‚¹è¿é€šæ€§æµ‹è¯•")
        print("=" * 60)
        
        # 1. æ£€æŸ¥æ–‡ä»¶
        if not self.check_sub_file():
            return None
        
        # 2. è¯»å–å†…å®¹
        content = self.read_subscription()
        if not content:
            return None
        
        # 3. æå–èŠ‚ç‚¹
        nodes = self.extract_nodes(content)
        if not nodes:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆèŠ‚ç‚¹")
            return None
        
        # é™åˆ¶æµ‹è¯•æ•°é‡é¿å…è¶…æ—¶
        test_nodes = nodes[:20]
        print(f"ğŸ§ª æµ‹è¯•å‰ {len(test_nodes)} ä¸ªèŠ‚ç‚¹")
        
        results = []
        
        # å¹¶å‘æµ‹è¯•
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            for i, node_url in enumerate(test_nodes, 1):
                future = executor.submit(self.test_single_node, node_url, i)
                futures.append(future)
            
            for i, future in enumerate(as_completed(futures), 1):
                try:
                    result = future.result()
                    results.append(result)
                    
                    # å®æ—¶æ˜¾ç¤ºè¿›åº¦
                    icon = 'âœ…' if result['status'] == 'success' else 'âŒ'
                    latency_info = f"{result['latency']:.1f}ms" if result['latency'] else "è¶…æ—¶"
                    
                    print(f"{icon} [{result['index']:2d}] {result['info']['type']:10} {result['info']['address']:15} å»¶è¿Ÿ: {latency_info}")
                    
                except Exception as e:
                    print(f"ğŸ’¥ æµ‹è¯•å¼‚å¸¸: {e}")
        
        return self.generate_report(results)
    
    def generate_report(self, results):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•æŠ¥å‘Š")
        print("=" * 60)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total = len(results)
        success_nodes = [r for r in results if r['status'] == 'success']
        success_count = len(success_nodes)
        
        print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»èŠ‚ç‚¹æ•°: {total}")
        print(f"   âœ… è¿é€šæ­£å¸¸: {success_count}")
        print(f"   âŒ è¿æ¥å¤±è´¥: {total - success_count}")
        print(f"   ğŸ“Š æˆåŠŸç‡: {success_count/total*100:.1f}%")
        
        # æ˜¾ç¤ºæœ€ä½³èŠ‚ç‚¹
        if success_nodes:
            success_nodes.sort(key=lambda x: x['latency'] or float('inf'))
            
            print(f"\nğŸ† æœ€ä½³èŠ‚ç‚¹ (æŒ‰å»¶è¿Ÿæ’åº):")
            for i, node in enumerate(success_nodes[:10], 1):
                info = node['info']
                print(f"{i:2d}. {info['type']:10} {info['address']:15}:{info.get('port', '?'):5} å»¶è¿Ÿ: {node['latency']:6.1f}ms")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        report_data = {
            'test_time': time.strftime('%Y-%m-%d %H:%M:%S'),
            'total_nodes': total,
            'successful_nodes': success_count,
            'success_rate': round(success_count/total*100, 1),
            'top_nodes': [
                {
                    'type': node['info']['type'],
                    'address': node['info']['address'],
                    'port': node['info'].get('port'),
                    'latency': node['latency'],
                    'remark': node['info'].get('remark', '')
                }
                for node in success_nodes[:5]
            ]
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open('test_results.json', 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: test_results.json")
        
        return report_data

def main():
    """ä¸»å‡½æ•°"""
    tester = GitHubNodeTester()
    results = tester.run_test()
    
    # è®¾ç½®GitHub Actionsè¾“å‡º
    if results and os.getenv('GITHUB_ACTIONS'):
        success_rate = results['success_rate']
        best_latency = results['top_nodes'][0]['latency'] if results['top_nodes'] else 0
        
        print(f"::set-output name=success_rate::{success_rate}")
        print(f"::set-output name=best_latency::{best_latency}")
        print(f"::set-output name=total_nodes::{results['total_nodes']}")

if __name__ == "__main__":
    main()
