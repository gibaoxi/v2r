#!/usr/bin/env python3
"""
é«˜é€Ÿä»£ç†è¿é€šæ€§æµ‹è¯•å·¥å…·
ä¸“æ³¨äºå¿«é€Ÿã€å‡†ç¡®çš„ä»£ç†èŠ‚ç‚¹æµ‹è¯•
"""

import asyncio
import aiohttp
import time
import json
import random
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from urllib.parse import urlparse
import base64
import re

@dataclass
class ProxyConfig:
    """ä»£ç†é…ç½®"""
    url: str
    protocol: str
    host: str
    port: int
    name: str = ""
    latency: float = 0.0
    status: str = "pending"
    error: str = ""
    tcp_connected: bool = False  # TCPè¿æ¥çŠ¶æ€

class FastProxyTester:
    def __init__(self, max_concurrent=50, timeout=8, tcp_timeout=3):
        self.max_concurrent = max_concurrent
        self.timeout = timeout
        self.tcp_timeout = tcp_timeout  # TCPè¿æ¥è¶…æ—¶æ—¶é—´
        self.semaphore = asyncio.Semaphore(max_concurrent)
        
        # æµ‹è¯•ç›®æ ‡ï¼ˆé€‰æ‹©å“åº”å¿«çš„ç½‘ç«™ï¼‰
        self.test_targets = [
            "https://ip.sb/",
            "https://httpbin.org/ip",
            "https://api.ipify.org?format=json"
        ]
    
    def parse_proxy_links(self, file_path: str) -> List[ProxyConfig]:
        """ä»æ–‡ä»¶è§£æä»£ç†é“¾æ¥"""
        configs = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'):
                        continue
                    
                    config = self._parse_single_link(line)
                    if config:
                        configs.append(config)
            
            print(f"âœ… è§£æå®Œæˆ: {len(configs)} ä¸ªä»£ç†é…ç½®")
            return configs
            
        except Exception as e:
            print(f"âŒâŒ è§£ææ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def _parse_single_link(self, link: str) -> Optional[ProxyConfig]:
        """è§£æå•ä¸ªä»£ç†é“¾æ¥"""
        try:
            if link.startswith('ss://'):
                return self._parse_ss(link)
            elif link.startswith('vmess://'):
                return self._parse_vmess(link)
            elif link.startswith('trojan://'):
                return self._parse_trojan(link)
            elif link.startswith('vless://'):
                return self._parse_vless(link)
            else:
                return None
        except:
            return None
    
    def _parse_ss(self, link: str) -> Optional[ProxyConfig]:
        """è§£æSSé“¾æ¥"""
        try:
            # ss://method:password@host:port#name
            if '#' in link:
                link, name = link.split('#', 1)
                name = name.strip()
            else:
                name = "SS-Node"
            
            # æå–åŸºç¡€éƒ¨åˆ†
            if '@' in link:
                user_info, server_part = link[5:].split('@', 1)
            else:
                # å¤„ç†base64ç¼–ç çš„æ ¼å¼
                b64_part = link[5:].split('#')[0]
                decoded = base64.b64decode(b64_part + '==').decode()
                user_info, server_part = decoded.split('@', 1)
            
            host, port = server_part.split(':', 1)
            port = int(port)
            
            return ProxyConfig(
                url=link,
                protocol="ss",
                host=host,
                port=port,
                name=name
            )
        except:
            return None
    
    def _parse_vmess(self, link: str) -> Optional[ProxyConfig]:
        """è§£æVMessé“¾æ¥"""
        try:
            b64_data = link[8:].split('#')[0]
            decoded = base64.b64decode(b64_data + '==').decode()
            config = json.loads(decoded)
            
            name = config.get('ps', 'VMess-Node')
            host = config.get('add', '')
            port = int(config.get('port', 443))
            
            return ProxyConfig(
                url=link,
                protocol="vmess",
                host=host,
                port=port,
                name=name
            )
        except:
            return None
    
    def _parse_trojan(self, link: str) -> Optional[ProxyConfig]:
        """è§£æTrojané“¾æ¥"""
        try:
            parsed = urlparse(link)
            host = parsed.hostname
            port = parsed.port or 443
            name = parsed.fragment or "Trojan-Node"
            
            return ProxyConfig(
                url=link,
                protocol="trojan",
                host=host,
                port=port,
                name=name
            )
        except:
            return None
    
    def _parse_vless(self, link: str) -> Optional[ProxyConfig]:
        """è§£æVLESSé“¾æ¥"""
        try:
            parsed = urlparse(link)
            host = parsed.hostname
            port = parsed.port or 443
            name = parsed.fragment or "VLESS-Node"
            
            return ProxyConfig(
                url=link,
                protocol="vless",
                host=host,
                port=port,
                name=name
            )
        except:
            return None
    
    async def test_tcp_connectivity(self, config: ProxyConfig) -> bool:
        """æµ‹è¯•TCPè¿é€šæ€§"""
        try:
            # å¼‚æ­¥TCPè¿æ¥æµ‹è¯•
            reader, writer = await asyncio.wait_for(
                asyncio.open_connection(config.host, config.port),
                timeout=self.tcp_timeout
            )
            writer.close()
            await writer.wait_closed()
            return True
        except (asyncio.TimeoutError, ConnectionRefusedError, OSError) as e:
            return False
        except Exception as e:
            return False
    
    async def test_single_proxy(self, config: ProxyConfig) -> ProxyConfig:
        """æµ‹è¯•å•ä¸ªä»£ç†"""
        async with self.semaphore:
            start_time = time.time()
            
            try:
                # ç¬¬ä¸€æ­¥ï¼šå…ˆè¿›è¡ŒTCPè¿æ¥æµ‹è¯•
                tcp_start = time.time()
                tcp_connected = await self.test_tcp_connectivity(config)
                tcp_latency = (time.time() - tcp_start) * 1000
                
                if not tcp_connected:
                    config.status = "tcp_failed"
                    config.error = "TCPè¿æ¥å¤±è´¥"
                    config.latency = round(tcp_latency, 2)
                    return config
                
                config.tcp_connected = True
                
                # ç¬¬äºŒæ­¥ï¼šTCPæµ‹è¯•æˆåŠŸï¼Œè¿›è¡ŒHTTPè®¿é—®æµ‹è¯•
                async with aiohttp.ClientSession() as session:
                    # éšæœºé€‰æ‹©ä¸€ä¸ªæµ‹è¯•ç›®æ ‡
                    test_url = random.choice(self.test_targets)
                    
                    proxy_url = self._build_proxy_url(config)
                    
                    async with session.get(
                        test_url,
                        proxy=proxy_url,
                        timeout=aiohttp.ClientTimeout(total=self.timeout),
                        headers={'User-Agent': 'Mozilla/5.0'}
                    ) as response:
                        if response.status in [200, 204]:
                            total_latency = (time.time() - start_time) * 1000
                            config.latency = round(total_latency, 2)
                            config.status = "success"
                        else:
                            config.status = "http_failed"
                            config.error = f"HTTP {response.status}"
                
            except asyncio.TimeoutError:
                config.status = "timeout"
                config.error = "è¯·æ±‚è¶…æ—¶"
            except Exception as e:
                config.status = "error"
                config.error = str(e)
            
            return config
    
    def _build_proxy_url(self, config: ProxyConfig) -> str:
        """æ„å»ºä»£ç†URL"""
        if config.protocol == "ss":
            return f"socks5://{config.host}:{config.port}"
        elif config.protocol in ["vmess", "vless", "trojan"]:
            return f"socks5://{config.host}:{config.port}"
        else:
            return f"http://{config.host}:{config.port}"
    
    async def batch_test(self, configs: List[ProxyConfig]) -> List[ProxyConfig]:
        """æ‰¹é‡æµ‹è¯•ä»£ç†"""
        print(f"ğŸš€ğŸš€ å¼€å§‹æµ‹è¯• {len(configs)} ä¸ªä»£ç†èŠ‚ç‚¹...")
        print(f"âš¡âš¡ å¹¶å‘æ•°: {self.max_concurrent}, TCPè¶…æ—¶: {self.tcp_timeout}ç§’, HTTPè¶…æ—¶: {self.timeout}ç§’")
        
        tasks = [self.test_single_proxy(config) for config in configs]
        
        # æ˜¾ç¤ºè¿›åº¦
        completed = 0
        total = len(tasks)
        
        for i, task in enumerate(asyncio.as_completed(tasks)):
            result = await task
            completed += 1
            
            # æ¯å®Œæˆ10ä¸ªæˆ–æœ€åæ˜¾ç¤ºè¿›åº¦
            if completed % 10 == 0 or completed == total:
                success_count = len([c for c in configs if c.status == "success"])
                tcp_success_count = len([c for c in configs if c.tcp_connected])
                print(f"ğŸ“ŠğŸ“Š è¿›åº¦: {completed}/{total} | TCPæˆåŠŸ: {tcp_success_count} | HTTPæˆåŠŸ: {success_count}")
        
        return configs
    
    def save_results(self, configs: List[ProxyConfig], output_file: str):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        # æŒ‰å»¶è¿Ÿæ’åº
        working_configs = [c for c in configs if c.status == "success"]
        working_configs.sort(key=lambda x: x.latency)
        
        tcp_success_configs = [c for c in configs if c.tcp_connected and c.status != "success"]
        failed_configs = [c for c in configs if not c.tcp_connected]
        
        # ä¿å­˜å¯ç”¨èŠ‚ç‚¹
        with open(f"working_{output_file}", 'w', encoding='utf-8') as f:
            for config in working_configs:
                f.write(f"{config.url} # {config.latency}ms\n")
        
        # ä¿å­˜TCPæˆåŠŸä½†HTTPå¤±è´¥çš„èŠ‚ç‚¹
        with open(f"tcp_only_{output_file}", 'w', encoding='utf-8') as f:
            for config in tcp_success_configs:
                f.write(f"{config.url} # TCPæˆåŠŸä½†HTTPå¤±è´¥: {config.error}\n")
        
        # ä¿å­˜å…¨éƒ¨ç»“æœï¼ˆå«ç»Ÿè®¡ï¼‰
        with open(f"full_{output_file}", 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("ä»£ç†è¿é€šæ€§æµ‹è¯•æŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æ€»èŠ‚ç‚¹æ•°: {len(configs)}\n")
            f.write(f"TCPè¿æ¥æˆåŠŸ: {len([c for c in configs if c.tcp_connected])}\n")
            f.write(f"HTTPæµ‹è¯•æˆåŠŸ: {len(working_configs)}\n")
            f.write(f"TCPæˆåŠŸä½†HTTPå¤±è´¥: {len(tcp_success_configs)}\n")
            f.write(f"TCPè¿æ¥å¤±è´¥: {len(failed_configs)}\n")
            f.write(f"æœ€ç»ˆæˆåŠŸç‡: {len(working_configs)/len(configs)*100:.1f}%\n\n")
            
            if working_configs:
                f.write("ğŸ†ğŸ† æœ€å¿«çš„å‰10ä¸ªèŠ‚ç‚¹:\n")
                for i, config in enumerate(working_configs[:10], 1):
                    f.write(f"{i:2d}. {config.latency:6.1f}ms - {config.name}\n")
                    f.write(f"    {config.url}\n\n")
            
            # æ˜¾ç¤ºTCPæˆåŠŸä½†HTTPå¤±è´¥çš„èŠ‚ç‚¹
            if tcp_success_configs:
                f.write("\n" + "=" * 60 + "\n")
                f.write("TCPæˆåŠŸä½†HTTPå¤±è´¥çš„èŠ‚ç‚¹:\n")
                f.write("=" * 60 + "\n")
                for config in tcp_success_configs:
                    f.write(f"{config.url} # é”™è¯¯: {config.error}\n")
            
            f.write("\n" + "=" * 60 + "\n")
            f.write("æ‰€æœ‰å¯ç”¨èŠ‚ç‚¹:\n")
            f.write("=" * 60 + "\n")
            for config in working_configs:
                f.write(f"{config.url} # {config.latency}ms\n")
        
        print(f"âœ… ç»“æœå·²ä¿å­˜:")
        print(f"   ğŸ“ å¯ç”¨èŠ‚ç‚¹: working_{output_file}")
        print(f"   ğŸ“ TCP-only: tcp_only_{output_file}")
        print(f"   ğŸ“Š å®Œæ•´æŠ¥å‘Š: full_{output_file}")
    
    def print_statistics(self, configs: List[ProxyConfig]):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        working = [c for c in configs if c.status == "success"]
        tcp_success = [c for c in configs if c.tcp_connected]
        tcp_only = [c for c in configs if c.tcp_connected and c.status != "success"]
        tcp_failed = [c for c in configs if not c.tcp_connected]
        
        print("\n" + "=" * 60)
        print("ğŸ“ˆğŸ“ˆ æµ‹è¯•ç»Ÿè®¡æŠ¥å‘Š")
        print("=" * 60)
        print(f"æ€»èŠ‚ç‚¹æ•°: {len(configs)}")
        print(f"TCPè¿æ¥æˆåŠŸ: {len(tcp_success)} ({len(tcp_success)/len(configs)*100:.1f}%)")
        print(f"HTTPæµ‹è¯•æˆåŠŸ: {len(working)} ({len(working)/len(configs)*100:.1f}%)")
        print(f"TCPæˆåŠŸä½†HTTPå¤±è´¥: {len(tcp_only)}")
        print(f"TCPè¿æ¥å¤±è´¥: {len(tcp_failed)}")
        
        if working:
            # å»¶è¿Ÿç»Ÿè®¡
            latencies = [c.latency for c in working]
            avg_latency = sum(latencies) / len(latencies)
            min_latency = min(latencies)
            max_latency = max(latencies)
            
            print(f"\nâ±â±â±ï¸ å»¶è¿Ÿç»Ÿè®¡:")
            print(f"  å¹³å‡: {avg_latency:.1f}ms")
            print(f"  æœ€ä½: {min_latency:.1f}ms")
            print(f"  æœ€é«˜: {max_latency:.1f}ms")
            
            # æŒ‰åè®®ç»Ÿè®¡
            protocol_stats = {}
            for config in working:
                protocol_stats[config.protocol] = protocol_stats.get(config.protocol, 0) + 1
            
            print(f"\nğŸ“¡ğŸ“¡ åè®®åˆ†å¸ƒ:")
            for protocol, count in protocol_stats.items():
                percentage = count / len(working) * 100
                print(f"  {protocol.upper():>10}: {count:>3} ({percentage:.1f}%)")
            
            # æ˜¾ç¤ºæœ€å¿«èŠ‚ç‚¹
            fastest = sorted(working, key=lambda x: x.latency)[:5]
            print(f"\nğŸ†ğŸ† æœ€å¿«çš„å‰5ä¸ªèŠ‚ç‚¹:")
            for i, config in enumerate(fastest, 1):
                print(f"  {i}. {config.latency:5.1f}ms - {config.name}")
        
        # æ˜¾ç¤ºTCPè¿æ¥ç»Ÿè®¡
        if tcp_only:
            print(f"\nâš ï¸âš ï¸ TCPæˆåŠŸä½†HTTPå¤±è´¥çš„èŠ‚ç‚¹ ({len(tcp_only)} ä¸ª):")
            error_stats = {}
            for config in tcp_only:
                error_stats[config.error] = error_stats.get(config.error, 0) + 1
            
            for error, count in error_stats.items():
                print(f"  {error}: {count} ä¸ª")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ğŸš€ é«˜é€Ÿä»£ç†è¿é€šæ€§æµ‹è¯•å·¥å…· (å¢å¼ºç‰ˆ - TCPä¼˜å…ˆæµ‹è¯•)")
    print("=" * 50)
    
    # é…ç½®å‚æ•°
    input_file = "all_configs.txt"  # ä½ çš„ä»£ç†åˆ—è¡¨æ–‡ä»¶
    output_file = "proxy_test_results.txt"
    max_concurrent = 30    # å¹¶å‘æ•°ï¼ˆå¯æ ¹æ®ç½‘ç»œè°ƒæ•´ï¼‰
    timeout = 6            # HTTPè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    tcp_timeout = 3        # TCPè¿æ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = FastProxyTester(
        max_concurrent=max_concurrent, 
        timeout=timeout, 
        tcp_timeout=tcp_timeout
    )
    
    # è§£æä»£ç†é…ç½®
    configs = tester.parse_proxy_links(input_file)
    if not configs:
        print("âŒâŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„ä»£ç†é…ç½®")
        return
    
    # å¼€å§‹æµ‹è¯•
    start_time = time.time()
    results = await tester.batch_test(configs)
    end_time = time.time()
    
    # æ˜¾ç¤ºç»“æœ
    tester.print_statistics(results)
    
    # ä¿å­˜ç»“æœ
    tester.save_results(results, output_file)
    
    # æ˜¾ç¤ºæ€»è€—æ—¶
    total_time = end_time - start_time
    print(f"\nâ°â°â° æ€»è€—æ—¶: {total_time:.1f}ç§’")
    print(f"ğŸ“ŠğŸ“Š æµ‹è¯•é€Ÿåº¦: {len(configs)/total_time:.1f} èŠ‚ç‚¹/ç§’")

if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    asyncio.run(main())
